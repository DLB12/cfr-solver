This project uses CFR to find the optimal strategies, represented as probability distributions of frequencies of folding, checking/calling, betting/raising, to avoid exploitability at various decision points. CFR is particularly useful in imperfect information games like poker because it allows an AI to approximate a Nash Equilibrium without knowing the opponent's private cards. It works by iteratively playing out hands against itself. And then (yo lowkey dont know if you are allowed to start a sentence with And but also it works here ngl), after each game, the solver calculates the "regret" for each decision made, which is the difference between the payoff of the action actually taken and the payoff of the best possible action it could have taken in hindsight. Over millions of iterations, the algorithm adjusts its strategy to minimize this cumulative regret, eventually converging on an unexploitable strategy that balances bluffing and value betting.

The solver operates on 100 fixed boards given an information set containing imperfect information a poker player would know. To begin, we restrict the infinite number of possible community card runouts to a representative set of 100 pre-generated "fixed boards" (sequences of Flop, Turn, and River cards). This ensures the AI learns strategies across different scenarios such as flush draws, paired boards, or disconnected  boards without needing to simulate every possible random outcome, allowing the training loop to converge efficiently.

Every information set at a given game state where a decision must be made by the player is representable as a string. The string (information set key) contains the player's hand, board, then betting history. In particular, the player's hand is represented as the corresponding two integers in increasing order, and the board is also represented by the integers corresponding to the cards in increasing order. Since players are restricted to only one betting/raising amount and there is a limit to the number of raises on a street, it is unambiguous and feasible to represent the entire betting history as a sequence of letters "r", "k", "c", "f" representing "raise", "check", "call", and "fold" respectively (with separation between actions taken at different streets). Note that this representation is meant for ease of interpretation, and in actual implementation the information set is hashed through the Polynomial Rolling Hash to increase efficiency. One prime is used to hash the player hand and board, while a different prime is used to hash the betting history. Note that the betting history is partitioned character by character, and each character is converted to its ASCII integer value.

To train a machine learning model that identifies the optimal strategy in an arbitrary board, we use the information sets and Nash Equilibrium strategies at different decision points of the 100 fixed boards as training data and the labels (we can reserve a portion for testing). Instead of using the raw representations or hashed representations of the information sets, we can use lists of one-hot vectors or multi-hot vectors to represent the player hand and board. The betting history can be summarized into a few crucial features (ie. total number of raises) concatenated into a vector, or the raw representation of the betting history can directly be converted into a vector. Together, these representations of the player hand, board, and betting history constitute the features the model trains on.
